{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165902af",
   "metadata": {},
   "source": [
    "#### Microphone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5806943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import soundfile as sf\n",
    "import time\n",
    "import wave\n",
    "import speech_recognition as sr \n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# NOTE: speech_recognition is no longer needed for the time-based recording method.\n",
    "# It would only be needed if you wanted to add back a VAD-based recording method.\n",
    "\n",
    "class Microphone:\n",
    "    def __init__(self, mic_index: int = 4, sample_rate: int = 44100):\n",
    "        \"\"\"\n",
    "        Initializes the Microphone utility class.\n",
    "        \n",
    "        Args:\n",
    "            mic_index (int): The index of the microphone to use. Run list_all_devices() to see options.\n",
    "            sample_rate (int): The sample rate to capture audio at.\n",
    "        \"\"\"\n",
    "        self.format = pyaudio.paInt16      # 16-bit resolution\n",
    "        self.channels = 1                  # Mono\n",
    "        self.sample_rate = sample_rate            # Samples per second\n",
    "        self.chunk = 1024                  # Samples per frame\n",
    "        self.mic_index = mic_index\n",
    "        self.audio_interface = pyaudio.PyAudio()\n",
    "\n",
    "    def list_all_devices(self):\n",
    "        \"\"\"\n",
    "        Lists all available audio input devices found by PyAudio.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Available Audio Input Devices ---\")\n",
    "        device_count = self.audio_interface.get_device_count()\n",
    "        if device_count == 0:\n",
    "            print(\"No audio devices found.\")\n",
    "            return\n",
    "\n",
    "        for i in range(device_count):\n",
    "            try:\n",
    "                device_info = self.audio_interface.get_device_info_by_index(i)\n",
    "                if device_info.get('maxInputChannels') > 0:\n",
    "                    print(f\"Device Index: {i}\")\n",
    "                    print(f\"  Name: {device_info.get('name')}\")\n",
    "                    print(f\"  Max Input Channels: {device_info.get('maxInputChannels')}\")\n",
    "                    print(f\"  Default Sample Rate: {int(device_info.get('defaultSampleRate'))} Hz\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not get info for device index {i}: {e}\")\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "    \n",
    "    def inspect_audio(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Inspects an audio file and prints its key properties.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the audio file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            info = sf.info(file_path)\n",
    "            print(\"\\n--- Audio File Information ---\")\n",
    "            print(f\"File Path:    {file_path}\")\n",
    "            print(f\"Sample Rate:  {info.samplerate} Hz\")\n",
    "            print(f\"Channels:     {info.channels}\")\n",
    "            print(f\"Duration:     {info.duration:.2f} seconds\")\n",
    "            print(f\"Format:       {info.format_info}\")\n",
    "            print(\"----------------------------\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error inspecting file: {e}\")\n",
    "            print(\"Please ensure the file path is correct and it's a valid audio file.\")\n",
    "\n",
    "\n",
    "    def record(self, duration: int = 5) -> str:\n",
    "        \"\"\"\n",
    "        Records audio from the microphone for a fixed duration.\n",
    "        The filename is automatically generated based on the current timestamp.\n",
    "\n",
    "        Args:\n",
    "            duration (int): The number of seconds to record for.\n",
    "        \n",
    "        Returns:\n",
    "            str: The filename of the saved audio.\n",
    "        \"\"\"\n",
    "        print(f\"\\nPreparing to record for {duration} seconds...\")\n",
    "        \n",
    "        stream = self.audio_interface.open(\n",
    "            format=self.format,\n",
    "            channels=self.channels,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk,\n",
    "            input_device_index=self.mic_index\n",
    "        )\n",
    "        \n",
    "        print(\"üî¥ Recording started...\")\n",
    "        \n",
    "        frames = []\n",
    "        # Loop to record audio chunk by chunk for the specified duration\n",
    "        for _ in range(0, int(self.sample_rate / self.chunk * duration)):\n",
    "            # --- THE FIX: Add exception_on_overflow=False to stream.read() ---\n",
    "            # This tells the stream to not crash if it overflows.\n",
    "            data = stream.read(self.chunk, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "            \n",
    "        print(\"‚úÖ Recording finished.\")\n",
    "        \n",
    "        # Stop and close the audio stream\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        \n",
    "        # Generate filename with timestamp\n",
    "        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        file_path = f\"recording_at_{timestamp}.wav\"\n",
    "\n",
    "        # Save the recorded data as a WAV file\n",
    "        with wave.open(file_path, 'wb') as wf:\n",
    "            wf.setnchannels(self.channels)\n",
    "            wf.setsampwidth(self.audio_interface.get_sample_size(self.format))\n",
    "            wf.setframerate(self.sample_rate)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "            \n",
    "        print(f\"Audio successfully saved to {file_path}\")\n",
    "        return file_path\n",
    "\n",
    "\n",
    "    # Record with VAD by recognition lib \n",
    "    def record_with_vad(self, audio_path: str = 'output.wav', timeout: int = 10, phrase_time_limit = 7): \n",
    "        recognizer = sr.Recognizer() \n",
    "        recognizer.pause_threshold = 2.0 # 2 seconds \n",
    "\n",
    "        source = sr.Microphone(device_index= self.mic_index, sample_rate= self.sample_rate )\n",
    "\n",
    "        # Calibrate for ambient noise         \n",
    "        print('Calibrating gfor ambient noise, please wait...')\n",
    "        with source as mic: # Wait, whaht ?? \n",
    "            recognizer.adjust_for_ambient_noise(mic)\n",
    "            print('Calibration complete. Listening for speech....')\n",
    "\n",
    "         \n",
    "            try: \n",
    "                audio_data = recognizer.listen(mic, \n",
    "                                               timeout= timeout)\n",
    "\n",
    "                print('Speech detected! Saving the recording...')\n",
    "\n",
    "                with open(audio_path, 'wb') as file: \n",
    "                    file.write(audio_data.get_wav_data())\n",
    "                \n",
    "                print(f'Audio sucessfully save to: {audio_path}')\n",
    "                return audio_path\n",
    "\n",
    "            except sr.WaitTimeoutError as e: \n",
    "                print(f'No speech detected within the timeout period')\n",
    "                return None \n",
    "            except Exception as e: \n",
    "                print(f'An error occurred: {e}')\n",
    "                return None \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f33718",
   "metadata": {},
   "source": [
    "#### Silero VAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8650e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import pyaudio\n",
    "import time \n",
    "import wave \n",
    "\n",
    "class Silero_VAD: \n",
    "    def __init__(self, sample_rate = 16000, chunk_size=512): \n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        print(\"Loading Silero VAD model...\")\n",
    "        self.model, _  = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                                        model='silero_vad', \n",
    "                                        force_reload=False) # <-- FIX #2: Prevents re-downloading\n",
    "\n",
    "        self.audio_interface = pyaudio.PyAudio() \n",
    "        print(\"VAD initialized successfully.\")\n",
    "\n",
    "    def listen(self, silence_chunks_needed=8): \n",
    "        # create a stream \n",
    "        stream = self.audio_interface.open(\n",
    "            format=pyaudio.paInt16, \n",
    "            channels=1, \n",
    "            rate=self.sample_rate, \n",
    "            input=True, \n",
    "            frames_per_buffer=self.chunk_size\n",
    "        )\n",
    "\n",
    "        # listen loop \n",
    "        print('\\nüé§ Listening for speech...')\n",
    "        recorded_frames = [] \n",
    "        is_speaking = False \n",
    "        silence_counter = 0 \n",
    "        \n",
    "        while True: \n",
    "            audio_chunk = stream.read(self.chunk_size)\n",
    "            audio_int16 = torch.from_numpy(np.frombuffer(audio_chunk, dtype=np.int16))\n",
    "            audio_float32 = audio_int16.to(torch.float32) / 32768.0 \n",
    "\n",
    "            speech_confidence = self.model(audio_float32, self.sample_rate).item() \n",
    "            \n",
    "            if speech_confidence > 0.5: \n",
    "                if not is_speaking: \n",
    "                    print(\"   (Speech started...)\")\n",
    "                    is_speaking = True \n",
    "                silence_counter = 0 \n",
    "                recorded_frames.append(audio_chunk)\n",
    "            \n",
    "            elif is_speaking:\n",
    "                silence_counter += 1 \n",
    "                recorded_frames.append(audio_chunk)\n",
    "                if silence_counter > silence_chunks_needed: \n",
    "                    print(\"   (Speech ended due to pause.)\")\n",
    "                    break \n",
    "            \n",
    "        stream.stop_stream() \n",
    "        stream.close() \n",
    "\n",
    "        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        file_path = f\"silero_vad_{timestamp}.wav\"\n",
    "        \n",
    "        with wave.open(file_path, 'wb') as wf:\n",
    "            wf.setnchannels(1)\n",
    "            wf.setsampwidth(self.audio_interface.get_sample_size(pyaudio.paInt16))\n",
    "            wf.setframerate(self.sample_rate)\n",
    "            wf.writeframes(b''.join(recorded_frames))\n",
    "            \n",
    "        print(f\"‚úÖ Recording saved to: {file_path}\")\n",
    "        return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa21190",
   "metadata": {},
   "source": [
    "#### PhoASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75028ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import argparse\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "from typing import Optional\n",
    "\n",
    "class PhoASR:\n",
    "    \"\"\"\n",
    "    A class to handle Vietnamese speech-to-text transcription using PhoWhisper models.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"vinai/PhoWhisper-base\"):\n",
    "        \"\"\"\n",
    "        Initializes the PhoASR transcriber.\n",
    "\n",
    "        This method loads the specified PhoWhisper model and processor from Hugging Face\n",
    "        and prepares them for transcription, automatically selecting the best available device (GPU or CPU).\n",
    "\n",
    "        Args:\n",
    "            model_name (str): The name of the PhoWhisper model to use from Hugging Face.\n",
    "                              Examples: \"vinai/PhoWhisper-small\", \"vinai/PhoWhisper-base\".\n",
    "        \"\"\"\n",
    "        print(f\"--- Initializing PhoASR with model: '{model_name}' ---\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_name = model_name\n",
    "        self.processor = None\n",
    "        self.model = None\n",
    "\n",
    "        try:\n",
    "            self.processor = WhisperProcessor.from_pretrained(self.model_name)\n",
    "            self.model = WhisperForConditionalGeneration.from_pretrained(self.model_name).to(self.device)\n",
    "            print(f\"‚úÖ Model loaded successfully on device: '{self.device}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "            print(\"Please check the model name and your internet connection.\")\n",
    "            # Set model to None to prevent usage if initialization fails\n",
    "            self.model = None\n",
    "\n",
    "    def transcribe(self, audio_path: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Transcribes an audio file into Vietnamese text.\n",
    "\n",
    "        Args:\n",
    "            audio_path (str): The path to the audio file (e.g., 'recording.wav', 'song.mp3').\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The transcribed text as a string, or None if an error occurs.\n",
    "        \"\"\"\n",
    "        if not self.model or not self.processor:\n",
    "            print(\"‚ùå Model not initialized. Cannot transcribe.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"\\n--- Processing Audio File: {audio_path} ---\")\n",
    "        try:\n",
    "            # Load the audio file. librosa automatically resamples it to 16,000 Hz,\n",
    "            # which is required by the Whisper model.\n",
    "            speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "            print(f\"Audio loaded and resampled to {sampling_rate} Hz.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading audio file: {e}\")\n",
    "            print(\"Please check the file path and ensure it is a valid audio format.\")\n",
    "            return None\n",
    "            \n",
    "        print(\"Transcribing... (This may take a moment)\")\n",
    "        \n",
    "        # Preprocess the audio waveform to create input features for the model\n",
    "        input_features = self.processor(\n",
    "            speech_array, \n",
    "            sampling_rate=16000, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.to(self.device)\n",
    "        \n",
    "        # Generate the sequence of token IDs from the input features\n",
    "        # We explicitly set the task and language for better performance and to avoid warnings.\n",
    "        predicted_ids = self.model.generate(\n",
    "            input_features, \n",
    "            task=\"transcribe\", \n",
    "            language=\"vi\"\n",
    "        )\n",
    "        \n",
    "        # Decode the token IDs back into a human-readable text string\n",
    "        transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        print(\"‚úÖ Transcription complete.\")\n",
    "        return transcription\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c62d6b",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e18e395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Silero VAD model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lequocthinh/.cache/torch/hub/snakers4_silero-vad_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAD initialized successfully.\n",
      "--- Initializing PhoASR with model: 'vinai/PhoWhisper-base' ---\n",
      "‚úÖ Model loaded successfully on device: 'cuda'.\n",
      "\n",
      "========================================\n",
      "ü§ñ AI Waiter is ready to take orders.\n",
      "========================================\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-11.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-11.wav ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: cho t√¥i hai c√°i vi da.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-19.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-19.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: t√¥i mu·ªën ƒÉn m·ªôt t∆∞ ph·ªü.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-31.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-31.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: t√¥i mu·ªën ƒÉn m·ªôt t√¥ m√¨ t√¥m.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-37.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-37.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: t√¥i mu·ªën ƒÉn m·ªôt t√¥m b·ªã t√¥m.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-46.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-46.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: cho t√¥i m·ªôt b√°t ph·ªü.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-51.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-51.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: cho t√¥i m·ªôt dƒ©a c∆°m tr·∫Øng.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-01-55.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-01-55.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: t√¥i bu√¥ng c·∫•t.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-02-01.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-02-01.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: cho t√¥i m·ªôt cu·ªôc th·ª©c.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "   (Speech started...)\n",
      "   (Speech ended due to pause.)\n",
      "‚úÖ Recording saved to: silero_vad_2025-10-04_23-02-08.wav\n",
      "\n",
      "--- Processing Audio File: silero_vad_2025-10-04_23-02-08.wav ---\n",
      "Audio loaded and resampled to 16000 Hz.\n",
      "Transcribing... (This may take a moment)\n",
      "‚úÖ Transcription complete.\n",
      "üë§ CUSTOMER SAID: gi·∫≠t v√© m√†y.\n",
      "ü§ñ AI WAITER SAYS: V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "üé§ Listening for speech...\n",
      "\n",
      "Conversation ended by user. Shutting down.\n"
     ]
    }
   ],
   "source": [
    "vad = Silero_VAD() \n",
    "asr = PhoASR()\n",
    "\n",
    "is_active = True\n",
    "print(\"\\n========================================\")\n",
    "print(\"ü§ñ AI Waiter is ready to take orders.\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# --- The Conversation Loop ---\n",
    "while is_active:\n",
    "    try:\n",
    "        # 1. Listen for customer speech using the VAD\n",
    "        customer_audio_file = vad.listen()\n",
    "\n",
    "        # 2. Transcribe the captured audio file using PhoWhisper\n",
    "        customer_text = asr.transcribe(customer_audio_file)\n",
    "        print(f\"üë§ CUSTOMER SAID: {customer_text}\")\n",
    "\n",
    "        # 3. (Future Step) Process text with NLU and get a response\n",
    "        if \"t·∫°m bi·ªát\" in customer_text.lower():\n",
    "            is_active = False\n",
    "            response = \"C·∫£m ∆°n qu√Ω kh√°ch. H·∫πn g·∫∑p l·∫°i!\"\n",
    "        else:\n",
    "            response = \"V√¢ng ·∫°, t√¥i ƒë√£ hi·ªÉu. Qu√Ω kh√°ch c√≤n y√™u c·∫ßu g√¨ n·ªØa kh√¥ng?\"\n",
    "        \n",
    "        # 4. (Future Step) Speak the response using TTS\n",
    "        print(f\"ü§ñ AI WAITER SAYS: {response}\")\n",
    "        # speak(response)\n",
    "\n",
    "        print(\"\\n--------------------------------------\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nConversation ended by user. Shutting down.\")\n",
    "        is_active = False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        is_active = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637f5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
