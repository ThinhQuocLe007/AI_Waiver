{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c961517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "hf_token = os.getenv('HUGGING_FACE_HUB_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3a526",
   "metadata": {},
   "source": [
    "### [ TEST ] LLAMA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama3 import LlamaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Llama model \n",
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "try: \n",
    "    print(f'Initializing {model_name}...') \n",
    "    llama = LlamaModel(\n",
    "        model_name= model_name, \n",
    "        hf_token= hf_token, \n",
    "        device= 'auto',\n",
    "        quantize= True\n",
    "    )\n",
    "    print('\\u2705 Llama Model created successfully')\n",
    "\n",
    "except Exception as e: \n",
    "    print(f'\\u274c Error when creating Llama model: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38027786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "print('Load Llama model')\n",
    "llama.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74562957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test discuss with model \n",
    "test_prompts = [\n",
    "    \"Hello, how are you today?\",\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me about Vietnamese food.\",\n",
    "    \"Explain machine learning in simple terms.\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts: \n",
    "    print(f'\\n Prompt: {prompt}')\n",
    "    try: \n",
    "        response = llama.generate_text(\n",
    "            prompt= prompt, \n",
    "            max_new_tokens= 100, \n",
    "            temperature= 0.7\n",
    "        )\n",
    "\n",
    "        print(f'[RESPONSE]: {response}')\n",
    "    except Exception as e: \n",
    "        print(f'\\u247c Generate error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfdf19",
   "metadata": {},
   "source": [
    "### [ TEST ] RAG SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_system import RAGSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95389f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the rag system \n",
    "menu_file_path = 'menu.json'\n",
    "\n",
    "try: \n",
    "    rag = RAGSystem(menu_file_path)\n",
    "    print(f'System status: {rag.get_stats()}')\n",
    "except Exception as e: \n",
    "    print(f'Initialize failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814be4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic search \n",
    "search_queries = [\n",
    "    (\"ph·ªü b√≤\", \"Vietnamese beef pho\"),\n",
    "    (\"g·ªèi cu·ªën\", \"Fresh spring rolls\"),\n",
    "    (\"b√∫n b√≤ Hu·∫ø\", \"Hue-style beef noodle soup\"),\n",
    "    (\"c√† ph√™\", \"Vietnamese coffee\"),\n",
    "    (\"ch·∫£ gi√≤\", \"Fried spring rolls\"),\n",
    "    (\"c∆°m t·∫•m\", \"Broken rice\"),\n",
    "    (\"spicy soup\", \"Spicy soup dishes\"),\n",
    "    (\"grilled meat\", \"Grilled meat dishes\"),\n",
    "    (\"cold drink\", \"Cold beverages\"),\n",
    "    (\"appetizer\", \"Starter dishes\")\n",
    "]\n",
    "\n",
    "for query, description in search_queries: \n",
    "    print(f'{description} : {query}')\n",
    "\n",
    "    try: \n",
    "        results = rag.search_index(query, top_k= 3, threshold= 0.2)\n",
    "\n",
    "        if results: \n",
    "            print(f'Found {len(results)} results')\n",
    "            for i, result in enumerate(results, 1): \n",
    "                print(f\"   {i}. {result['name']} (Score: {result['similarity_score']:.3f})\")\n",
    "                print(f\"      Price: {result['price']} VND | Category: {result['category']}\")\n",
    "        else: \n",
    "            print('No results found')\n",
    "    except Exception as e: \n",
    "        print(f'Search failed: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Context Generation for Vietnamese Restaurant Scenarios\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST 2: Context Generation for Vietnamese Restaurant Scenarios\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Qu√°n c√≥ nh·ªØng m√≥n ph·ªü g√¨?\", \"What pho dishes do you have?\"),\n",
    "    (\"Cho t√¥i xem c√°c m√≥n khai v·ªã\", \"Show me appetizers\"),\n",
    "    (\"T√¥i mu·ªën ƒÉn m√≥n cay cay\", \"I want something spicy\"),\n",
    "    (\"C√≥ nh·ªØng ƒë·ªì u·ªëng g√¨?\", \"What drinks are available?\"),\n",
    "    (\"M√≥n c∆°m n√†o c√≥ th·ªãt n∆∞·ªõng?\", \"Rice dishes with grilled meat\"),\n",
    "    (\"M√≥n ƒÉn truy·ªÅn th·ªëng Vi·ªát Nam\", \"Traditional Vietnamese food\"),\n",
    "    (\"ƒê·ªì u·ªëng m√°t l·∫°nh\", \"Cold refreshing drinks\"),\n",
    "    (\"C√°c m√≥n c√≥ th·ªãt heo\", \"Pork dishes\"),\n",
    "    (\"M√≥n ƒÉn nh·∫π ƒë·ªÉ ƒÉn ch∆°i\", \"Light snacks/appetizers\"),\n",
    "    (\"B√∫n n√†o ngon nh·∫•t?\", \"Which noodle soup is best?\"),\n",
    "    (\"C√≥ m√≥n chay kh√¥ng?\", \"Do you have vegetarian dishes?\"),\n",
    "    (\"M√≥n ƒÉn cho tr·ªùi n√≥ng\", \"Food for hot weather\"),\n",
    "    (\"C√† ph√™ Vi·ªát Nam\", \"Vietnamese coffee\"),\n",
    "    (\"M√≥n cu·ªën t∆∞∆°i m√°t\", \"Fresh spring rolls\"),\n",
    "    (\"ƒê·∫∑c s·∫£n mi·ªÅn Nam\", \"Southern Vietnamese specialties\")\n",
    "]\n",
    "\n",
    "for scenario_vn, scenario_en in scenarios:\n",
    "    print(f\"\\nüí≠ Vietnamese: '{scenario_vn}'\")\n",
    "    print(f\"   English: '{scenario_en}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Test with Vietnamese query\n",
    "        context = rag.get_context_for_llms(scenario_vn, top_k=3)\n",
    "        print(\"üìã Context Generated:\")\n",
    "        print(context)\n",
    "        \n",
    "        # Check if results were found\n",
    "        if \"No relevant menu items found\" in context:\n",
    "            print(\"‚ö†Ô∏è  No results with Vietnamese query, trying English...\")\n",
    "            context_en = rag.get_context_for_llms(scenario_en, top_k=3)\n",
    "            if \"No relevant menu items found\" not in context_en:\n",
    "                print(\"üìã Context with English query:\")\n",
    "                print(context_en)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Context generation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e610f",
   "metadata": {},
   "source": [
    "### AI Waiter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_chatbot import AIWaiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0427941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Llama model \n",
    "model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "menu_file_path = 'menu.json'\n",
    "\n",
    "waiter = AIWaiter(menu_file_path, model_name, hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce42092",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Hello! What do you recommend?\",\n",
    "    \"T√¥i mu·ªën ƒÉn ph·ªü. C√≥ lo·∫°i n√†o?\",\n",
    "    \"I want something spicy and filling\",\n",
    "    \"What appetizers do you have?\",\n",
    "    \"M√≥n n√†o r·∫ª nh·∫•t?\",\n",
    "    \"Show me your coffee options\"\n",
    "]\n",
    "\n",
    "for query in test_queries: \n",
    "    print(f'Customer: {query}')\n",
    "    response = waiter.chat(query)\n",
    "    print(f'Linh: {response}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb4f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
