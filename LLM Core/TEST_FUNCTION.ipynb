{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a018b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather in Tokyo? Also, calculate tip for a $50 bill with 20% tip.\n",
      "\n",
      "ðŸ¤– AI is calling functions...\n",
      "\n",
      "ðŸ“ž Calling: get_weather({'city': 'Tokyo'})\n",
      "ðŸ“‹ Result: Cloudy, 25Â°C\n",
      "\n",
      "ðŸ“ž Calling: calculate_tip({'bill_amount': 50, 'tip_percentage': 20})\n",
      "ðŸ“‹ Result: Bill: $50, Tip (20%): $10.00, Total: $60.00\n",
      "\n",
      "ðŸ¤– AI Assistant: Please note that the weather forecast is subject to change and might not be up-to-date. For the most accurate and current information, I recommend checking a reliable weather website or app.\n",
      "\n",
      "Also, please note that tipping customs may vary in different regions, and it's always a good idea to check local norms before leaving a tip.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "# Initialize the Ollama client\n",
    "client = ollama.Client()\n",
    "\n",
    "# Define some simple functions\n",
    "def get_weather(city):\n",
    "    \"\"\"Get the weather for a specific city\"\"\"\n",
    "    # Simulate weather data\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 72Â°F\",\n",
    "        \"London\": \"Rainy, 15Â°C\", \n",
    "        \"Tokyo\": \"Cloudy, 25Â°C\",\n",
    "        \"Paris\": \"Partly cloudy, 18Â°C\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"Weather data not available for {city}\")\n",
    "\n",
    "def calculate_tip(bill_amount, tip_percentage=15):\n",
    "    \"\"\"Calculate tip amount\"\"\"\n",
    "    tip = (bill_amount * tip_percentage) / 100\n",
    "    total = bill_amount + tip\n",
    "    return f\"Bill: ${bill_amount}, Tip ({tip_percentage}%): ${tip:.2f}, Total: ${total:.2f}\"\n",
    "\n",
    "# Available functions mapping\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculate_tip\": calculate_tip\n",
    "}\n",
    "\n",
    "# Define tools for the model\n",
    "tools = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'get_weather',\n",
    "            'description': 'Get current weather information for a city',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'city': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The city name to get weather for'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['city']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'calculate_tip',\n",
    "            'description': 'Calculate tip and total amount for a bill',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'bill_amount': {\n",
    "                        'type': 'number',\n",
    "                        'description': 'The bill amount in dollars'\n",
    "                    },\n",
    "                    'tip_percentage': {\n",
    "                        'type': 'number',\n",
    "                        'description': 'Tip percentage (default: 15)',\n",
    "                        'default': 15\n",
    "                    }\n",
    "                },\n",
    "                'required': ['bill_amount']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# User message\n",
    "user_message = \"What's the weather in Tokyo? Also, calculate tip for a $50 bill with 20% tip.\"\n",
    "\n",
    "# Conversation history\n",
    "messages = [\n",
    "    {'role': 'user', 'content': user_message}\n",
    "]\n",
    "\n",
    "print(f\"User: {user_message}\\n\")\n",
    "\n",
    "# First call: Let the model decide which tools to use\n",
    "response = client.chat(\n",
    "    model='llama3.1:latest',\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Check if the model wants to call any functions\n",
    "if response['message'].get('tool_calls'):\n",
    "    print(\"ðŸ¤– AI is calling functions...\\n\")\n",
    "    \n",
    "    # Add the AI's response to conversation\n",
    "    messages.append(response['message'])\n",
    "    \n",
    "    # Process each function call\n",
    "    for call in response['message']['tool_calls']:\n",
    "        function_name = call['function']['name']\n",
    "        \n",
    "        # Handle arguments (could be string or dict)\n",
    "        if isinstance(call['function']['arguments'], str):\n",
    "            function_args = json.loads(call['function']['arguments'])\n",
    "        else:\n",
    "            function_args = call['function']['arguments']\n",
    "        \n",
    "        print(f\"ðŸ“ž Calling: {function_name}({function_args})\")\n",
    "        \n",
    "        # Call the actual function\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_response = function_to_call(**function_args)\n",
    "        \n",
    "        print(f\"ðŸ“‹ Result: {function_response}\\n\")\n",
    "        \n",
    "        # Add function result to conversation\n",
    "        messages.append({\n",
    "            'role': 'tool',\n",
    "            'content': function_response,\n",
    "        })\n",
    "\n",
    "# Second call: Get the final response\n",
    "final_response = client.chat(\n",
    "    model='llama3.1:latest',\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(f\"ðŸ¤– AI Assistant: {final_response['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29201708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
